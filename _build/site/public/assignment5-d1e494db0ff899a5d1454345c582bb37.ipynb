{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df52a4df",
   "metadata": {},
   "source": [
    "# Assignment 5: EMS Clusters\n",
    "## CSci 39542: Introduction to Data Science\n",
    "**Department of Computer Science\n",
    "Hunter College, City University of New York**\n",
    "**Fall 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa4463",
   "metadata": {},
   "source": [
    "### Program 5: EMS Clusters.   \n",
    "*Due Midnight, Wednesday, 3 December.*\n",
    "\n",
    "**Learning Objective**: to enhance data cleaning skills and build understanding of clustering algorithms.\n",
    "\n",
    "**Available Libraries**: pandas, datetime, sklearn, and core Python 3.6+.\n",
    "\n",
    "**Data Sources**: [911 System Calls (NYC OpenData)](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data)\n",
    "\n",
    "**Sample Datasets**:\n",
    "Small dataset (1 day of calls for 1 borough): [NYPD_Calls_Manhattan_4Jul2021.csv](../attachments/NYPD_Calls_Manhattan_4Jul2021.csv),\n",
    "\n",
    "Midnight calls in January 2021 (all boroughs): [NYPD_Calls_midnight_Jan2021.csv](../attachments/NYPD_Calls_midnight_Jan2021.csv),\n",
    "\n",
    "Larger dataset (1 month of calls for Queens): [NYPD_Calls_Queens_Jan2021.csv](../attachments//NYPD_Calls_Queens_Jan2021.csv)\n",
    "\n",
    "\n",
    "For this program, we are building on the clustering techniques from Lecture 11 and Classwork 11.1 which focused on different clustering algorithms. Decreasing ambulance response times improves outcomes and [strategic placement](../attachments/Andersson%20et%20al.%20-%202020%20-%20Using%20optimization%20to%20provide%20decision%20support%20for%20strategic%20emergency%20medical%20service%20planning%20–%20Th.pdf) of ambulance stations and overall allocation has been shown an effective approach. For example, here are all the calls for ambulances on 4 July 2021 in Manhattan ([using Folium/Leaflet to create an interactive map](../attachments/4_July_map.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f59f9c",
   "metadata": {},
   "source": [
    "To decide on where to \"pre-place\" ambulances, we will start with K-means clustering, where \"K\" is the number of ambulances available for that shift. For example, if there 2 ambulances available to be placed in Manhattan, we will look at previous ambulance calls for that shift and form 2 clusters and station each ambulance at the mean of the cluster. If two more ambulances become available, we can recompute the K-means algorithm for K=4, and place those 4 ambulances, each at the mean of the cluster found, and similarly for K=8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e60be",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"width: 30%;\">\n",
    "        <img src=\"../attachments/july4_clusters2.png\" alt=\"Cluster 2\" style=\"width: 100%; height: auto;\"/>\n",
    "    </div>\n",
    "    <div style=\"width: 30%;\">\n",
    "        <img src=\"../attachments/july4_clusters4.png\" alt=\"Cluster 4\" style=\"width: 100%; height: auto;\"/>\n",
    "    </div>\n",
    "    <div style=\"width: 30%;\">\n",
    "        <img src=\"../attachments/july4_clusters8.png\" alt=\"Cluster 8\" style=\"width: 100%; height: auto;\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722d11e",
   "metadata": {},
   "source": [
    "In addition to K-means analysis, we will also compare to other clustering techniques and use standard approaches from [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html) as well as filter data by time and day.\n",
    "\n",
    "[![image](../attachments/sphx_glr_plot_cluster_comparison_001.png)](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67dc22",
   "metadata": {},
   "source": [
    "The program follows standard strategy for data cleaning and model building:\n",
    "\n",
    "Read in datasets, merging and cleaning as needed.\n",
    "Split our dataset into training and testing sets.\n",
    "Fit a model, or multiple models, to the training dataset.\n",
    "Validate the models using the testing dataset.\n",
    "Develop test suites, using pytest, to ensure that correctness of the code written.\n",
    "To download test datasets, see [Program 2](../notebooks/assignment2.ipynb) for directions on accessing datasets at NYC Open Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f6fb09",
   "metadata": {},
   "source": [
    "#### Preparing Data\n",
    "\n",
    "Once you have downloaded some test data sets to your device, the next thing to do is format the data to be usable for analysis. We will need to do some cleaning, and also filter by day of week and time. Once we have the cleaned the data, we can split it into training and testing data sets. Add the following functions to your Python program:\n",
    "\n",
    "- `make_df(file_name)`: This function takes one input:\n",
    "  - `file_name`: the name of a CSV file containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd) from OpenData NYC.\n",
    "\n",
    "The data is read into a DataFrame. Rows that are have null values for the type description, incident date, incident time, latitute and longitude are dropped. Only rows that contain `AMBULANCE` as part of the `TYP_DESC` are kept. The resulting DataFrame is returned.\n",
    "\n",
    "*Hint: see [DS 100: Chapter 13](https://learningds.org/ch/13/text_strings.html) for using string methods within pandas.*\n",
    "\n",
    "- `add_date_time_features(df)`: This function takes one input:\n",
    "  - `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd) from OpenData NYC created by `make_df`.\n",
    "  \n",
    "An additional column `WEEK_DAY` is added with the day of the week (0 for Monday, 1 for Tuesday, ..., 6 for Sunday) of the date in `INCIDENT_DATE` is added. Another column, `INCIDENT_MIN`, that takes the time from `INCIDENT_TIME` and stores it as the number of minutes since midnight. The resulting DataFrame is returned.\n",
    "\n",
    "*Hint: see previous lectures for using datetime methods with pandas, including computing the day of the week (of `datetime` objects) and the total seconds (of `timedelta` objects).*\n",
    "\n",
    "- `filter_by_time(df, days=None, start_min=0, end_min=1439)`: This function takes four inputs:\n",
    "  - `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd) from OpenData NYC.\n",
    "  - `days`: a list of integers ranging from 0 to 6, representing the days of the week. The default value is None and is equivalent to the list containing all days: `[0,1,2,3,4,5,6]`.\n",
    "  - `start_min`: a non-negative integer value representing the starting time. With `end_min`, it representing the range, inclusive, for the time, in minutes, that should be selected. The default value give the range of `[0,1439]` which ranges from midnight (`0` minutes) to (`1439` representing 23:59 since 23 hours + 59 minutes = 23*60+59 minutes = 1439 minutes).\n",
    "  - `end_min`: a non-negative integer value representing the ending time. With `start_min`, it representing the range, inclusive, for the time, in minutes, that should be selected. The default value give the range of `[0,1439]` which ranges from midnight (`0` minutes) to (`1439` representing 23:59 since 23 hours + 59 minutes = 23*60+59 minutes = 1439 minutes).\n",
    "  \n",
    "Returns a DataFrame with entries restricted to weekdays in `days` (or all weekdays if `None` is given) and incident times in `[start_min, end_min]` inclusive (e.g. contains the endpoints).\n",
    "\n",
    "\n",
    "For example, if we use the small dataset from 4 July 2021:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da0505",
   "metadata": {},
   "source": [
    "```python\n",
    "df = make_df('NYPD_Calls_Manhattan_4Jul2021.csv')\n",
    "print(df[['INCIDENT_TIME','TYP_DESC','Latitude','Longitude']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7e4ab",
   "metadata": {},
   "source": [
    "would print:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91629829",
   "metadata": {},
   "source": [
    "```text\n",
    "     INCIDENT_TIME                             TYP_DESC   Latitude  Longitude\n",
    "7         00:01:51      AMBULANCE CASE: CARDIAC/OUTSIDE  40.724578 -73.992519\n",
    "27        00:06:12       AMBULANCE CASE: CARDIAC/INSIDE  40.807719 -73.964240\n",
    "51        00:12:12      AMBULANCE CASE: SERIOUS/TRANSIT  40.732019 -74.000734\n",
    "53        00:12:38           AMBULANCE CASE: EDP/INSIDE  40.789348 -73.947352\n",
    "54        00:12:38           AMBULANCE CASE: EDP/INSIDE  40.789348 -73.947352\n",
    "...            ...                                  ...        ...        ...\n",
    "5175      23:50:02         AMBULANCE CASE: WATER RESCUE  40.711839 -74.011234\n",
    "5176      23:50:02         AMBULANCE CASE: WATER RESCUE  40.711839 -74.011234\n",
    "5205      23:57:11  AMBULANCE CASE: UNCONSCIOUS/TRANSIT  40.732019 -74.000734\n",
    "5211      23:57:59           AMBULANCE CASE: EDP/INSIDE  40.827547 -73.937461\n",
    "5212      23:57:59           AMBULANCE CASE: EDP/INSIDE  40.827547 -73.937461\n",
    "\n",
    "[459 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5a88a",
   "metadata": {},
   "source": [
    "Note that the original CSV file had over 5000 lines, only 459 of those were for ambulances calls. The indices were not reset and refer to the line numbers of the original file.\n",
    "Let's add in the date and time features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5527b93b",
   "metadata": {},
   "source": [
    "```python\n",
    "df = add_date_time_features(df)\n",
    "print(df[['INCIDENT_DATE','WEEK_DAY','INCIDENT_TIME','INCIDENT_MIN']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bb6a53",
   "metadata": {},
   "source": [
    "would print:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff4bae",
   "metadata": {},
   "source": [
    "```text \n",
    "     INCIDENT_DATE  WEEK_DAY INCIDENT_TIME  INCIDENT_MIN\n",
    "7       07/04/2021         6      00:01:51      1.850000\n",
    "27      07/04/2021         6      00:06:12      6.200000\n",
    "51      07/04/2021         6      00:12:12     12.200000\n",
    "53      07/04/2021         6      00:12:38     12.633333\n",
    "54      07/04/2021         6      00:12:38     12.633333\n",
    "...            ...       ...           ...           ...\n",
    "5175    07/04/2021         6      23:50:02   1430.033333\n",
    "5176    07/04/2021         6      23:50:02   1430.033333\n",
    "5205    07/04/2021         6      23:57:11   1437.183333\n",
    "5211    07/04/2021         6      23:57:59   1437.983333\n",
    "5212    07/04/2021         6      23:57:59   1437.983333\n",
    "\n",
    "[459 rows x 4 columns]\n",
    "[Finished in 2.294s]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e8400",
   "metadata": {},
   "source": [
    "Since all the incidents are from a single day (i.e. 4 July 2021) the `WEEK_DAY` column has the same value (i.e. `6`) for every row.\n",
    "\n",
    "Let's add in the date and time features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86cb638",
   "metadata": {},
   "source": [
    "```python\n",
    "df_early_am = filter_by_time(df,times=[0,360])\n",
    "print(df_early_am[['INCIDENT_DATE','WEEK_DAY','INCIDENT_TIME','INCIDENT_MIN']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7b80f",
   "metadata": {},
   "source": [
    "would print:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8851e",
   "metadata": {},
   "source": [
    "```text\n",
    "     INCIDENT_DATE  WEEK_DAY INCIDENT_TIME  INCIDENT_MIN\n",
    "7       07/04/2021         6      00:01:51      1.850000\n",
    "27      07/04/2021         6      00:06:12      6.200000\n",
    "51      07/04/2021         6      00:12:12     12.200000\n",
    "53      07/04/2021         6      00:12:38     12.633333\n",
    "54      07/04/2021         6      00:12:38     12.633333\n",
    "...            ...       ...           ...           ...\n",
    "1041    07/04/2021         6      05:08:49    308.816667\n",
    "1068    07/04/2021         6      05:21:49    321.816667\n",
    "1075    07/04/2021         6      05:24:21    324.350000\n",
    "1079    07/04/2021         6      05:28:13    328.216667\n",
    "1111    07/04/2021         6      05:41:34    341.566667\n",
    "\n",
    "[76 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5cbb4",
   "metadata": {},
   "source": [
    "We can build a map with the calls for ambulances shaded by the time of the call:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb56db1",
   "metadata": {},
   "source": [
    "```python\n",
    "import folium\n",
    "import matplotlib.colors\n",
    "def cc(minute,scale):\n",
    "    return(matplotlib.colors.to_hex( (minute/scale,0,minute/scale) ))\n",
    "\n",
    "m = folium.Map(location=[40.7678,-73.9645],zoom_start=13,tiles=\"cartodbpositron\")\n",
    "df.apply( lambda row: folium.CircleMarker(location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
    "                                        radius=5, popup=(row['INCIDENT_TIME']+\": \"+row['TYP_DESC']),\n",
    "                                        color=cc(row['INCIDENT_MIN'],2000))\n",
    "                                        .add_to(m) ,\n",
    "        axis=1)\n",
    "m.save('4_July_map.html')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb93536",
   "metadata": {},
   "source": [
    "displayed above. Note that we used the time to shade the incidents. The popups provide the exact time as well as the description.\n",
    "\n",
    "#### Building Models\n",
    "\n",
    "Next, let's build some models, using the clustering techniques from previous lectures. Write the following functions:\n",
    "\n",
    "- `compute_kmeans(df, num_clusters = 8, n_init = 'auto', random_state = 1870)`: This function takes four inputs:\n",
    "  \n",
    "\t- `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data) from OpenData NYC\n",
    "\t- `n_init`: Number of times the k-means algorithm is run with different centroid seeds. The final results is the best output of `n_init` consecutive runs in terms of inertia. The default value is `auto`.\n",
    "\t- `num_clusters`: an integer representing the number of clusters. The default value is `8`.\n",
    "\t- `random_state`: the random seed used for [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). The default value is `1870`.\n",
    "  \n",
    "Runs the KMeans model with `num_clusters` on the latitude and longitude data of the provided DataFrame. Returns the cluster centers and predicted labels computed via the model.\n",
    "<!-- *A similar, but not identical function was part of Classwork 9.* -->\n",
    "\n",
    "- `compute_gmm(df, num_clusters = 8, random_state = 1870)`: This function takes three input:\n",
    "\t- `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data) from OpenData NYC.\n",
    "\t- `num_clusters`: an integer representing the number of clusters. The default value is `8`.\n",
    "\t- `random_state`: the random seed used for [GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture). The default value is `1870`.\n",
    "  \n",
    "Runs the GaussianMixture model with `num_clusters` on the latitude and longitude data of the provided DataFrame. Returns the array of the predicted labels computed via the model.\n",
    "\n",
    "- `compute_agglom(df, num_clusters = 8, linkage='ward')`: This function takes three inputs:\n",
    "\t- `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data) from OpenData NYC.\n",
    "\t- `num_clusters`: an integer representing the number of clusters. The default value is `8`.\n",
    "\t- `linkage`: the linkage criterion used determining distances between sets for [AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering). The default value is `'ward'`.\n",
    "  \n",
    "Runs the Agglomerative model with `num_clusters` on the latitude and longitude data of the provided DataFrame and default linkage (i.e. `ward`). Returns the array of the predicted labels computed via the model.\n",
    "\n",
    "- `compute_spectral(df, num_clusters = 8, affinity='rbf',random_state=1870)`: This function takes four inputs:\n",
    "\t- `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd/about_data) from OpenData NYC.\n",
    "\t- `num_clusters`: an integer representing the number of clusters. The default value is `8`.\n",
    "\t- `affinity`: method used for computing the affinity matrix by [SpectralClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html). The default value is `'rbf'`.\n",
    "\t- `random_state`: the random seed used for [SpectralClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html). The default value is `1870`.\n",
    "  \n",
    "Runs the Spectral Clustering model with `num_clusters` on the latitude and longitude data of the provided DataFrame and affinity matrix (i.e. `affinity`). Returns the array of the predicted labels computed via the model.\n",
    "\n",
    "We can also make maps with the computed clusters. We use the `compute_locations` function with different values of `num_clusters`. Since we are repeating the same actions for `K = 2, 4, 6`, we wrote a helper function to create the HTML maps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112412e2",
   "metadata": {},
   "source": [
    "```python\n",
    "def make_map(df, num_clusters, out_file):\n",
    "            centers,labels = compute_kmeans(df,num_clusters = num_clusters)\n",
    "            df_map = df[ ['Latitude','Longitude','INCIDENT_TIME','INCIDENT_MIN','TYP_DESC'] ]\n",
    "            df_map = df_map.assign(Labels = labels)\n",
    "            m = folium.Map(location=[40.7678,-73.9645],zoom_start=13,tiles=\"cartodbpositron\")\n",
    "            df_map.apply( lambda row: folium.CircleMarker(location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
    "                                                radius=5, popup=(row['INCIDENT_TIME']+\": \"+row['TYP_DESC']),\n",
    "                                                color=cc(row['Labels'],num_clusters))\n",
    "                                                .add_to(m), axis=1)\n",
    "            for i in range(num_clusters):\n",
    "                x,y = centers[i]\n",
    "                folium.Marker(location=[x,y],popup = \"Cluster \"+str(i)).add_to(m)\n",
    "            m.save(out_file)\n",
    "        \n",
    "        make_map(df,2,'map_4_July_2clusters.html')\n",
    "        make_map(df,4,'map_4_July_4clusters.html')\n",
    "        make_map(df,8,'map_4_July_8clusters.html')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99f61c",
   "metadata": {},
   "source": [
    "Screenshots of the maps are displayed above.\n",
    "\n",
    "Another function can be used to filter the dataset by day of the week and time of day. For example, still working with the 4 July data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dc1443",
   "metadata": {},
   "source": [
    "```python\n",
    "df_mondays = filter_by_time(df, days = [0])\n",
    "print(df_mondays)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bb3e6",
   "metadata": {},
   "source": [
    "This will return an empty DataFrame since only 4 of July in this data set (which was a Sunday and we filtered for 0 or Monday):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4ed68",
   "metadata": {},
   "source": [
    "```text\n",
    "Empty DataFrame\n",
    "        Columns: [CAD_EVNT_ID, CREATE_DATE, INCIDENT_DATE, INCIDENT_TIME, NYPD_PCT_CD, BORO_NM, PATRL_BORO_NM, GEO_CD_X, GEO_CD_Y, RADIO_CODE, TYP_DESC, CIP_JOBS, ADD_TS, DISP_TS, ARRIVD_TS, CLOSNG_TS, Latitude, Longitude, WEEK_DAY, INCIDENT_MIN]\n",
    "        Index: []\n",
    "111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bee281",
   "metadata": {},
   "source": [
    "Let's next filter for early morning times:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58279688",
   "metadata": {},
   "source": [
    "```python\n",
    "df_early_am = filter_by_time(df,times=[0,360])\n",
    "print(df_early_am[['INCIDENT_DATE','WEEK_DAY','INCIDENT_TIME','INCIDENT_MIN']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588b4a9",
   "metadata": {},
   "source": [
    "would print:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d72417",
   "metadata": {},
   "source": [
    "```text\n",
    "INCIDENT_DATE  WEEK_DAY INCIDENT_TIME  INCIDENT_MIN\n",
    "\t7       07/04/2021         6      00:01:51      1.850000\n",
    "\t27      07/04/2021         6      00:06:12      6.200000\n",
    "\t51      07/04/2021         6      00:12:12     12.200000\n",
    "\t53      07/04/2021         6      00:12:38     12.633333\n",
    "\t54      07/04/2021         6      00:12:38     12.633333\n",
    "\t...            ...       ...           ...           ...\n",
    "\t1041    07/04/2021         6      05:08:49    308.816667\n",
    "\t1068    07/04/2021         6      05:21:49    321.816667\n",
    "\t1075    07/04/2021         6      05:24:21    324.350000\n",
    "\t1079    07/04/2021         6      05:28:13    328.216667\n",
    "\t1111    07/04/2021         6      05:41:34    341.566667\n",
    "\n",
    "[76 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fd4c2",
   "metadata": {},
   "source": [
    "We can use other methods for clustering, printing out the labels for the uly 4 dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e748bd3",
   "metadata": {},
   "source": [
    "```python\n",
    "print(compute_gmm(df))\n",
    "print(compute_agglom(df))  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02d308",
   "metadata": {},
   "source": [
    "```text\n",
    "[1 7 1 0 0 1 1 0 0 4 0 2 1 5 5 2 2 1 1 4 4 4 4 5 1 6 3 5 3 3 7 0 7 1 3 3 3\n",
    "        3 1 2 2 7 6 1 1 1 2 0 0 4 5 3 4 6 6 3 1 3 3 1 6 4 6 0 6 6 3 2 6 3 1 1 1 1\n",
    "        4 4 5 2 1 2 2 7 7 1 1 5 3 1 0 5 5 4 4 2 0 0 0 0 2 2 4 4 3 1 1 7 4 3 3 6 6\n",
    "        2 1 0 3 3 1 5 5 2 3 3 1 1 5 5 2 2 0 2 2 3 2 2 1 5 5 1 5 0 0 0 2 2 1 1 5 2\n",
    "        1 3 0 5 5 5 1 1 2 0 0 7 7 7 6 6 3 3 4 4 1 1 1 1 1 3 1 7 4 4 0 1 5 1 3 7 0\n",
    "        4 4 3 1 3 3 0 0 0 0 1 1 1 6 6 0 0 0 0 5 2 2 5 5 3 4 4 1 4 2 0 2 0 2 2 1 1\n",
    "        1 3 3 1 3 3 1 0 0 5 5 1 5 5 1 7 5 2 1 0 0 0 1 5 2 0 2 1 4 4 1 1 4 7 7 3 3\n",
    "        4 1 1 7 7 5 5 0 1 5 1 1 0 7 0 0 2 0 7 7 5 1 2 3 1 1 1 1 3 6 6 4 5 5 2 2 0\n",
    "        3 0 0 2 5 5 0 1 3 7 7 5 5 3 0 6 0 0 1 2 4 5 2 1 3 3 1 1 2 0 1 2 2 2 3 3 4\n",
    "        4 5 5 1 2 0 3 4 3 3 0 1 6 1 1 4 1 4 4 3 6 6 6 2 2 2 3 6 3 3 1 0 5 3 5 2 2\n",
    "        3 3 6 6 2 2 3 6 6 2 0 0 3 3 2 0 3 2 2 3 3 4 4 6 6 1 6 4 5 5 5 4 6 1 1 1 4\n",
    "        2 0 3 5 2 1 3 1 4 3 1 0 3 5 5 5 3 3 7 3 1 2 2 2 4 4 2 2 2 1 1 3 3 2 3 5 1\n",
    "        1 1 0 0 0 0 4 4 5 6 6 6 1 2 2]\n",
    "        [0 6 0 3 3 0 0 3 3 2 3 4 0 7 7 4 4 0 0 2 2 2 2 7 0 0 1 0 1 1 6 3 1 0 1 1 1\n",
    "        1 0 4 4 4 5 0 0 0 4 3 3 2 3 1 2 0 0 1 0 1 1 0 0 2 0 3 0 0 1 4 0 1 0 0 0 0\n",
    "        2 2 3 4 0 4 4 1 1 1 0 3 1 0 3 7 7 2 2 4 3 3 3 3 4 4 2 2 1 0 0 6 2 1 1 0 0\n",
    "        4 0 4 1 1 0 0 0 4 1 1 0 0 7 7 4 4 3 4 4 1 4 4 0 7 7 0 7 3 3 3 4 4 0 0 7 4\n",
    "        0 1 3 7 0 0 0 0 4 3 3 6 6 4 5 5 1 1 2 2 0 0 0 0 0 1 0 6 2 2 3 0 7 0 1 6 3\n",
    "        2 2 1 0 0 0 3 3 3 3 0 0 0 0 5 3 3 3 3 7 4 4 7 7 1 2 2 0 4 4 3 4 6 4 4 0 0\n",
    "        0 1 1 0 1 1 0 3 3 7 7 0 3 3 0 6 3 4 0 3 3 3 0 7 4 3 4 0 2 4 0 0 2 6 6 1 1\n",
    "        2 0 0 6 6 3 3 3 0 7 5 5 3 6 3 3 4 3 6 6 0 0 4 1 0 0 0 0 1 5 5 2 7 7 4 4 3\n",
    "        1 3 3 4 7 7 3 0 1 6 6 7 7 7 3 0 3 3 0 4 2 7 4 0 1 1 1 1 4 3 0 4 4 4 1 1 2\n",
    "        2 0 0 0 4 3 1 2 1 1 3 0 5 0 0 2 0 2 2 1 5 5 5 4 4 4 1 5 1 1 0 3 7 1 3 4 4\n",
    "        1 1 5 5 4 4 1 0 0 4 3 3 1 1 4 3 1 4 4 1 1 2 2 5 5 0 5 2 7 3 3 2 5 0 0 0 2\n",
    "        4 4 1 7 4 0 1 0 2 1 0 3 1 7 3 3 1 1 6 1 0 4 4 4 2 2 4 4 4 0 0 1 1 4 1 3 0\n",
    "        0 0 3 3 3 3 2 2 3 5 5 5 0 4 4]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1888eb",
   "metadata": {},
   "source": [
    "#### Evaluating Models\n",
    "\n",
    "- `compute_explained_variance(df, k_vals = None, random_state = 1870)`: This function takes three inputs:\n",
    "\t- `df`: a DataFrame containing [911 System Calls](https://data.cityofnewyork.us/Public-Safety/NYPD-Calls-for-Service-Year-to-Date-/n2zq-pubd) from OpenData NYC.\n",
    "\t- `k_vals`: a list of integers representing values for the number of clusters. The no value is provided, the function uses `k_vals = [1,2,3,4,5]`.\n",
    "\t- `random_state`: the random seed used for KMeans. The default value is `55`.\n",
    "\n",
    "Returns a list of the sum of squared distances of samples to their closest cluster center for each value of `K`. This can be computed manually or via the `inertia_` attribute of the [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) model.\n",
    "\n",
    "We can use the function `compute_explained_variance` to assess the best number of clusters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a20f4",
   "metadata": {},
   "source": [
    "```python\n",
    "k_vals = list(range(1,20))\n",
    "ev = compute_explained_variance(df,K=k_vals)\n",
    "sns.lineplot(k_vals,ev)\n",
    "plt.title('Explained Variance for KMeans for Manhattan, 4 July 2021')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0a9da3",
   "metadata": {},
   "source": [
    "will display:\n",
    "![image](../attachments/july4_ev.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d5413",
   "metadata": {},
   "source": [
    "showing a sharp drop-off to `K=5` that quickly flattens, showing that additional clusters, beyond 10, do not significantly improve the average distance to the assigned means. This suggests that a reasonable number of clusters is around 8.\n",
    "\n",
    "#### Test Suites\n",
    "\n",
    "Each programming assignment includes functions that test that your code works (a \"test suite\"). In Programs 1 & 2, we wrote the test functions by hand. For Programs 3-6, we will also use [pytest](https://docs.pytest.org/en/7.4.x/), a standard Python testing framework. Before you start, make sure that your IDE has pytest installed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31769b",
   "metadata": {},
   "source": [
    "```text\n",
    "pip install -U pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7149b9b",
   "metadata": {},
   "source": [
    "Pytest is one of the most popular testing frameworks for Python. For this program, we will introduce the core testing features (and will introduce more features, such as parametrizing, in future programs). For more details, [pytest docs](https://docs.pytest.org/en/7.4.x/) and [Think CS: Chapter 20](https://runestone.academy/ns/books/published//thinkcspy/UnitTesting/toctree.html).\n",
    "\n",
    "- `test_add_date_time_features()`: This function takes no inputs. Returns True if the function `add_date_time_features` performs correctly and `False` otherwise.\n",
    "\n",
    "- `test_filter_by_time()`: This function takes no inputs. Returns True if the function `filter_by_time` performs correctly and False otherwise.\n",
    "\n",
    "Trying first on the correct function, assuming that your program is called `p5.py`, we can invoke `pytest` from the command-line:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1b42a",
   "metadata": {},
   "source": [
    "```text\n",
    "pytest p5.py::test_add_date_time_features\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974d5ae",
   "metadata": {},
   "source": [
    "gives the output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed7c43",
   "metadata": {},
   "source": [
    "```text\n",
    "======================================= test session starts ========================================\n",
    "  platform darwin -- Python 3.11.5, pytest-7.4.2, pluggy-1.3.0\n",
    "  rootdir: /Users/stjohn/gitHub/dataScience/programs/fall23/program05\n",
    "  collected 1 item                                                                                   \n",
    "  \n",
    "  p5.py .                                                                                      [100%]\n",
    "  \n",
    "  ======================================== 1 passed in 1.63s =========================================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc4c09",
   "metadata": {},
   "source": [
    "`pytest` looks for a function called: `test_add_date_time_features()` in the file p3.py. It then runs `test_add_date_time_features`, which tests the correctness of the function `add_date_time_features` and **reports** back the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
