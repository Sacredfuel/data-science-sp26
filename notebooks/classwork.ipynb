{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework\n",
    "\n",
    "## CSci 39542: Introduction to Data Science\n",
    "\n",
    "**Department of Computer Science, Hunter College, City University of New York**  \n",
    "**Spring 2026**\n",
    "\n",
    "---\n",
    "\n",
    "All students must join the course's gradescope using the provided access code: **PK36RW**. Students must verify that their Gradescope account has their full name and CUNY email address in the account settings (Account > Edit Account).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Unless otherwise noted, classwork is submitted via Gradescope. Access information is given during the corresponding lecture. To get the most out of lecture, bring a device with you to lecture with a development environment (IDE) that has Python 3+ (preferrably the same that you plan to use for technical interviews). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not say you were in the room if you did not attend.** Lying about attendance obtains an unfair advantage and will be submitted to the Office of Student Conduct. It is not worth the points (that would have been replaced anyway by your final exam score) for a record of academic dishonesty that is kept by both the department and college. The suggested sanction for lying is a 0 on this classwork and the loss of the replacement policy for missed lecture grades. Note: while we suggest a sanction, the final decision about the severity of the sanction is by the Office of Student Conduct. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 1\n",
    "\n",
    "#### Classwork 1\n",
    "\n",
    "*Due 11:30am, Thursday, 04 September.*  \n",
    "\n",
    "Available during Lecture 1 on Gradescope, this classwork introduces the autograder that is used for the programming assignments.  The structure of the sample program mirrors the structure and content of the upcoming Program 1 (which we will start in the second part of Lecture 1).  \n",
    "    \n",
    "Write a function that takes the name of a file and makes a dictionary of the lines of the file.\n",
    "          \n",
    "- `make_dict(file_name, sep=': ')`:  Takes a name of a file (file_name) and a delimiter (sep), where the default value is ': '.  If a line of the file does not include sep, the line should be ignored.   Otherwise, for each line, the string preceding the delimiter sep is the key, and the string after sep is the value.  Your function returns the dictionary.\n",
    "          \n",
    "For example, assuming these functions are in a file, `cw1.py` and run on a file containing names that start with 'A', [contacts.txt](../attachments/contacts.txt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = cw1.make_dict('contacts.txt')\n",
    "who = 'CS Department'\n",
    "print(f'Contact info for {who} is {contacts[who]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will print:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Contact info for CS Department is 10th Floor HN, x5213.`   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example with [nick_names.txt](../attachments/nick_names.txt): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nick_names = cw1.make_dict('nick_names.txt', sep = ' ')\n",
    "names = ['Beth','Lisa','Meg','Greta','Amy','Mia']\n",
    "for n in names:\n",
    "  print(f'Full name for {n} is {nick_names[n]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will print:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Full name for Beth is Elizabeth.\n",
    "    Full name for Lisa is Elizabeth.\n",
    "    Full name for Meg is Margaret.\n",
    "    Full name for Greta is Margaret.\n",
    "    Full name for Amy is Amelia.\n",
    "    Full name for Mia is Amelia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attended lecture, include the last line to the introductory comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name:  YOUR_NAME\n",
    "Email: YOUR_EMAIL\n",
    "Resources:  RESOURCES USED\n",
    "I attended lecture today.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did not attend lecture, do not include the last line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 2\n",
    "\n",
    "#### Classwork 2\n",
    "\n",
    "*Due 11:30am, Monday, 08 September.*  \n",
    "\n",
    "Available during Lecture 2 on Gradescope, this classwork asks that you write a program using Pandas and its file I/O. To get the most out of this exercise, bring a laptop with you to lecture with a development environment (IDE) that has Python 3.6+ to work through in lecture. \n",
    "    \n",
    "Write a program that asks the user for the name of an input CSV file and the name of an output CSV file. The program should open the file name provided by the user. Next, the program should select rows where the field `Grade` is equal to 3 and the `Year` is equal to 2019 and write all rows that match that criteria to a new CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then a sample run of the program: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "Enter input file name: school-ela-results-2013-2019.csv\n",
    "Enter output file name:  ela2013.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the file [school-ela-results-2013-2019.csv](../attachments/school_ELA_2013_2019.csv) is extracted from NYC Schools Test Results. The first lines of the output file would be: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "School,Name,Grade,Year,Category,Number Tested,Mean Scale Score,# Level 1,% Level 1,# Level 2,% Level 2,# Level 3,% Level 3,# Level 4,% Level 4,# Level 3+4,% Level 3+4\n",
    "01M015,P.S. 015 ROBERTO CLEMENTE,3,2019,All Students,27,606,1,3.7,7,25.9,18,66.7,1,3.7,19,70.4\n",
    "01M019, P.S. 019 ASHER LEVY,3,2019,All Students,24,606,0,0.0,8,33.3,15,62.5,1,4.2,16,66.7\n",
    "01M020,P.S. 020 ANNA SILVER,3,2019,All Students,57,593,13,22.8,24,42.1,18,31.6,2,3.5,20,35.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: \n",
    "\n",
    "* Since the `Grade` column contains a mixtures of numbers (e.g. 3) and strings (\"All Grades\"), the column is stored as strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attended lecture, include the last line in the introductory comment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Name:  YOUR_NAME\n",
    "Email: YOUR_EMAIL\n",
    "Resources:  RESOURCES USED\n",
    "I attended lecture today.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5\n",
    "\n",
    "#### Classwork 7\n",
    "\n",
    "*Due 11:59pm, Monday, 29 September.*  \n",
    "\n",
    "Available during Lecture 7 on Gradescope, this classwork focuses on hiring in the technical sector. 2022 fall, hiring looked quite strong. Here's a an analysis by [Prof. Stevenson](https://fordschool.umich.edu/faculty/betsey-stevenson) of University of Michigan:\n",
    "\n",
    "\n",
    "![stevenson_info_jobs_dec_2022.png](../attachments/stevenson_info_jobs_dec_2022.png)\n",
    "\n",
    "[BLS Monthly Jobs Report: Rapid Insights from Betsey Stevenson](https://poverty.umich.edu/2022/12/02/november-jobs-report-strong-job-growth-continues-but-there-are-hints-of-weakness/).\n",
    "\n",
    "Including more recent numbers show growth but not as quickly:\n",
    "\n",
    "<!-- Using the data set for the previous 5 years from [St. Louis Federal Reserve Economic Data Data (FRED)](https://fred.stlouisfed.org/series/USINFO): -->\n",
    "\n",
    "![tech_jobs_fred_1940_2023.png](../attachments/tech_jobs_fred_1940_2023.png)\n",
    "\n",
    "*Available Libraries: pandas, numpy, sklearn.linear_model, pickle.*\n",
    "\n",
    "Using the data set for 2010 until August 2023 from [St. Louis Federal Reserve Economic Data Data (FRED)](https://fred.stlouisfed.org/series/USINFO):\n",
    "\n",
    "\t[fred_info_2010_aug_2023.csv](../attachments/fred_info_2010_aug_2023.csv): A CSV file with the employment in Information Services since 2010 (until August 2023).\n",
    "write functions that will fit a linear regression to the data and predicts the number of jobs on January 1, 2024:\n",
    "\n",
    "- `fit_linear_regression(df)`: This function takes one input:\n",
    "\n",
    "\t- `df`: containing an index and the column, `USINFO`.\n",
    "\n",
    "Fits a linear model to `index` and `????`, using `sklearn.linear_model.LinearRegression` (see lecture & textbook for details on setting up the model). The resulting model should be returned as bytestream, using [pickle](https://docs.python.org/3/library/pickle.html) (see Lecture 4).\n",
    "\n",
    "*Hint: Since each entry is exactly 1 month apart, you can use the index, instead of parsing the datetime{.inline} objects. You may find `df.index.to_series()` useful.*\n",
    "\n",
    "`predict(mod_pkl, offset)`: This function takes two inputs:\n",
    "\n",
    "- `mod_pkl`: a trained model for the data, stored in pickle format.\n",
    "- `offset`: the number of months since January 1, 2010.\n",
    "  \n",
    "Using the model, `mod_pkl`, returns the predicted number of employees in Information Services `offset` months from January 1, 2010. For example if `offset` is `180`, then it would return the model's prediction of the number of employees `180/12 = 15` years after the baseline (January 2010) or January 2025. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(directory\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfred_info_2010_aug_2023.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m mod_pkl \u001b[38;5;241m=\u001b[39m fit_linear_regression(df)\n\u001b[1;32m      3\u001b[0m januarys \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m120\u001b[39m,\u001b[38;5;241m240\u001b[39m,\u001b[38;5;241m12\u001b[39m))})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(directory+'fred_info_2010_aug_2023.csv')\n",
    "mod_pkl = fit_linear_regression(df)\n",
    "januarys = pd.DataFrame({'index' : list(range(120,240,12))})\n",
    "predictions = predict(mod_pkl,januarys)\n",
    "print(f'The predicted employments by years:')\n",
    "results = zip(list(range(2020,2030)),predictions)\n",
    "for year,pred in results:\n",
    "    print(f'January {year}: \\t {int(pred*1000):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gives the model's predictions for employment from 2020 to 2030:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The predicted employments by years:\n",
    "January 2020:    2,879,867\n",
    "January 2021:    2,905,173\n",
    "January 2022:    2,930,480\n",
    "January 2023:    2,955,786\n",
    "January 2024:    2,981,092\n",
    "January 2025:    3,006,398\n",
    "January 2026:    3,031,705\n",
    "January 2027:    3,057,011\n",
    "January 2028:    3,082,317\n",
    "January 2029:    3,107,623\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6\n",
    "#### Classwork 9\n",
    "*Due 11:59pm, Thursday, 9 October.*\n",
    "Available during Lecture 9 on Gradescope, the learning objective of this classwork is to increase understanding of smoothing and gain fluidity with using distributions for smoothing. To get the most out of this exercise, bring a laptop with you to lecture with a development environment (IDE) that has Python 3.6+ to work through in lecture. \n",
    "\n",
    "In [Section 11.2](https://learningds.org/ch/11/viz_smoothing.html), we used smoothing to visualize data. For this program, write a function that takes two arguments, an Numpy array of x-axis coordinates, and a list of numeric values, and returns the corresponding y-values for the sum of the gaussian probability distribution functions (pdf's) for each point in the list.\n",
    "\n",
    "- `computeSmoothing(xes,points)`: This function takes a numpy array `xes` and a list, `points`, of numeric values. For each `p` in `points`, the function should compute the normal probability distribution function (`scipy.norm.pdf`) centered at `loc = p` with standard deviation `scale = 0.5` for all values in `xes`. The return value is a numpy array of the sum of these at each point.\n",
    "\n",
    "For example, calling the function:\n",
    "\n",
    "```\n",
    "xes = np.linspace(0, 10, 1000)\n",
    "density = computeSmoothing(xes,[5])\n",
    "plt.plot(xes,density)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "would give the plot:\n",
    "\n",
    "![](https://stjohn.github.io/teaching/data/fall21/density5.png)\n",
    "\n",
    "since there is only one point given (namely 5), the returned value is the probability density function centered at 5 (with `scale = 0.5`) computed for each of the `xes`.\n",
    "\n",
    "For example, calling the function:\n",
    "\n",
    "```\n",
    "pts = [2,2,5,5,2,3,4,6,7,9]\n",
    "xes = np.linspace(0, 10, 1000)\n",
    "density = computeSmoothing(xes,pts)\n",
    "plt.plot(xes,density)\n",
    "plt.fill_between(xes,density)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "would give the plot:\n",
    "\n",
    "![](https://stjohn.github.io/teaching/data/fall21/density_fillBetween.png)\n",
    "\n",
    "since the there are 10 points given, the function computes the probability density function centered at each of the points, across all the values in `xes`. It then sums up these contributions and returns an array of the same length as `xes`.\n",
    "\n",
    "Note: you should submit a file with only the standard comments at the top, and this function. The grading scripts will then import the file for testing. If you attended lecture, include in the introductory comment the three lines detailed in Classwork 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 7\n",
    "\n",
    "#### Classwork 10\n",
    "\n",
    "*Due 11:59pm, Tuesday, 14 October.*   \n",
    "Available during Lecture 10 on Gradescope, this classwork introduces the canonical digits dataset and uses sci-kit learn to build logistic regression\n",
    "models. To get the most out of this exercise, bring a laptop with you to\n",
    "lecture with a development environment (IDE) that has Python 3+ to work\n",
    "through in lecture.\n",
    "\n",
    "This program uses the canonical [MNIST dataset of hand-written\n",
    "digits](https://en.wikipedia.org/wiki/MNIST_database) and available in\n",
    "[sklearn digits dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mnist_digits.png](../attachments/sklearn_digits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 1797 scans of hand-written digits. Each entry has the\n",
    "digit represented (`target`) as well as the 64 values\n",
    "representing the gray scale for the 8 x 8 image. The first 5 entries\n",
    "are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray scales for the first 5 entries, flattened to one dimensional\n",
    "array:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` text\n",
    "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3. 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
    " [ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.  3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16. 16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n",
    " [ 0.  0.  0.  4. 15. 12.  0.  0.  0.  0.  3. 16. 15. 14.  0.  0.  0.  0.  8. 13.  8. 16.  0.  0.  0.  0.  1.  6. 15. 11.  0.  0.  0.  1.  8. 13. 15.  1.  0.  0.  0.  9. 16. 16.  5.  0.  0.  0.  0.  3. 13. 16. 16. 11.  5.  0.  0.  0.  0.  3. 11. 16.  9.  0.]\n",
    " [ 0.  0.  7. 15. 13.  1.  0.  0.  0.  8. 13.  6. 15.  4.  0.  0.  0.  2.  1. 13. 13.  0.  0.  0.  0.  0.  2. 15. 11.  1.  0.  0.  0.  0.  0.  1. 12. 12.  1.  0.  0.  0.  0.  0.  1. 10.  8.  0.  0.  0.  8.  4.  5. 14.  9.  0.  0.  0.  7. 13. 13.  9.  0.  0.]\n",
    " [ 0.  0.  0.  1. 11.  0.  0.  0.  0.  0.  0.  7.  8.  0.  0.  0.  0.  0.  1. 13.  6.  2.  2.  0.  0.  0.  7. 15.  0.  9.  8.  0.  0.  5. 16. 10.  0. 16.  6.  0.  0.  4. 15. 16. 13. 16.  1.  0.  0.  0.  0.  3. 15. 10.  0.  0.  0.  0.  0.  2. 16.  4.  0.  0.]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will focus on entries that represent 0\\'s and 1\\'s. The first\n",
    "10 from the dataset are displayed below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mnist_digits](../attachments/mnist_first5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that builds a logistic regression model that classifies\n",
    "binary digits:\n",
    "\n",
    "- `def binary_digit_clf(data, target, test_size = 0.25, random_state = 21):`:\n",
    "  This function has four inputs:\n",
    "  - `data`: a numpy array that includes rows of equal size\n",
    "    flattend arrays,\n",
    "  - `target` a numpy array that takes values 0 or 1\n",
    "    corresponding to the rows of `data`.\n",
    "  - `test_size`: the size of the test set created when the data\n",
    "    is divided into test and training sets with\n",
    "    [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "    The default value is `0.25`.\n",
    "  - `random_state`: the random seed used when the data is\n",
    "    divided into test and training sets with\n",
    "    [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "    The default value is `21`.\n",
    "\n",
    "  The function returns the [confusion\n",
    "  matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "  that results.\n",
    "\n",
    "For example, let\\'s flatten the entries and restrict the dataset to just\n",
    "binary digits:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#Import datasets, classifiers and performance metrics:\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Using the digits data set from sklearn:\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print(digits.target)\n",
    "print(type(digits.target), type(digits.data))\n",
    "#flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "print(data[0:5])\n",
    "print(f'The targets for the first 5 entries: {digits.target[:5]}')\n",
    "#Make a DataFrame with just the binary digits:\n",
    "binaryDigits = [(d,t) for (d,t) in zip(data,digits.target) if t <= 1]\n",
    "bd,bt = zip(*binaryDigits)\n",
    "print(f'The targets for the first 5 binary entries: {bt[:5]}')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will print:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` text\n",
    "\n",
    "[0 1 2 ... 8 9 8]\n",
    "   \n",
    "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
    "15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
    "0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
    "0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
    " [ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
    "3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
    "16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
    "0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n",
    " [ 0.  0.  0.  4. 15. 12.  0.  0.  0.  0.  3. 16. 15. 14.  0.  0.  0.  0.\n",
    "8. 13.  8. 16.  0.  0.  0.  0.  1.  6. 15. 11.  0.  0.  0.  1.  8. 13.\n",
    "15.  1.  0.  0.  0.  9. 16. 16.  5.  0.  0.  0.  0.  3. 13. 16. 16. 11.\n",
    "5.  0.  0.  0.  0.  3. 11. 16.  9.  0.]\n",
    " [ 0.  0.  7. 15. 13.  1.  0.  0.  0.  8. 13.  6. 15.  4.  0.  0.  0.  2.\n",
    "1. 13. 13.  0.  0.  0.  0.  0.  2. 15. 11.  1.  0.  0.  0.  0.  0.  1.\n",
    "12. 12.  1.  0.  0.  0.  0.  0.  1. 10.  8.  0.  0.  0.  8.  4.  5. 14.\n",
    "9.  0.  0.  0.  7. 13. 13.  9.  0.  0.]\n",
    " [ 0.  0.  0.  1. 11.  0.  0.  0.  0.  0.  0.  7.  8.  0.  0.  0.  0.  0.\n",
    "1. 13.  6.  2.  2.  0.  0.  0.  7. 15.  0.  9.  8.  0.  0.  5. 16. 10.\n",
    "0. 16.  6.  0.  0.  4. 15. 16. 13. 16.  1.  0.  0.  0.  0.  3. 15. 10.\n",
    "0.  0.  0.  0.  0.  2. 16.  4.  0.  0.]]\n",
    "The targets for the first 5 entries: [0 1 2 3 4]\n",
    "The targets for the first 5 binary entries: (0, 1, 0, 1, 0)\n",
    " \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the restricted data and targets datasets as input to our\n",
    "function, assuming your function `binary_digit_clf()`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "confuse_mx = binary_digit_clf(bd,bt,test_size=0.95)\n",
    "print(f'Confusion matrix:\\n{confuse_mx}')\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=confuse_mx)\n",
    "#Use a different color map since the default is garish:\n",
    "disp.plot(cmap = \"Purples\")\n",
    "plt.title(\"Logistic Regression Classifier for Binary Digits\")\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which will print:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Confusion matrix:\n",
    "[[172   0]\n",
    " [  4 166]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and display:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![log_confusion](../attachments/logReg_clf_confuse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example with the same data, but different size for the data\n",
    "reserved for testing:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "confuse_mx = binary_digit_clf(bd,bt)\n",
    "print(f'Confusion matrix:\\n{confuse_mx}')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "would print:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "Confusion matrix:\n",
    "[[43  0]\n",
    " [ 0 47]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: you should submit a file with only the standard comments at the\n",
    "top, and this function. The grading scripts will then import the file\n",
    "for testing. If you attended lecture, include in the introductory\n",
    "comment the three lines detailed in Classwork 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classwork 13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [Google Maps API](https://developers.google.com/maps/documentation/distance-matrix/overview), we generated the amount of time it would take to travel between the following landmarks:\n",
    "- Bronx Zoo (Bronx),\n",
    "- Empire State Building (Manhattan),\n",
    "- National Lighthouse Museum (Staten Island),\n",
    "- FDR Four Freedoms Park (Roosevelt Island),\n",
    "- Citi Field (Queens),\n",
    "- Coney Island (Brooklyn), and\n",
    "- Hunter College (Manhattan)\n",
    "\n",
    "by driving, transit, and walking (files: [nyc_landmarks_driving.csv](../attachments/nyc_landmarks_driving.csv), [nyc_landmarks_transit.csv](../attachments/nyc_landmarks_transit.csv), [nyc_landmarks_walking.csv](../attachments/nyc_landmarks_walking.csv)).\n",
    "\n",
    "Of the three, which best estimates the (aerial) distance?\n",
    "\n",
    "![nyc_landmarks_distance.png](../attachments/nyc_landmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12\n",
    "## Classwork 15:   \n",
    "*Monday, 17 November.*   \n",
    "Write a program that asks the user for the name of an input HTML file and the name of an output CSV file. Your program should use regular expressions (see Chapter 12.4 for using the re package in Python) to find all links in the input file and store the link text and URL as columns: Title and URL in the CSV file specified by the user. For the URL, strip off the leading https:// or http:// and any trailing slashes (/):\n",
    "\n",
    "For example, if the input file is:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` text\n",
    "<html>\n",
    "<head><title>Simple HTML File</title></head>\n",
    "\n",
    "<body>\n",
    "  <p> Here's a link for <a href=\"http://www.hunter.cuny.edu/csci\">Hunter CS Department</a>\n",
    "  and for <a href=\"https://stjohn.github.io/teaching/data/fall21/index.html\">CSci 39542</a>.  </p>\n",
    "\n",
    "  <p> And for <a href=\"https://www.google.com/\">google</a>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a sample run of the program:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Enter input file name: simple.html\n",
    "Enter output file name:  links.csv\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the links.csv would be:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Title,URL\n",
    "Hunter CS Department,www.hunter.cuny.edu/csci\n",
    "CSci 39542,stjohn.github.io/teaching/data/fall21/index.html\n",
    "google,www.google.com\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you should submit a file with only the standard comments at the top that you attended lecture in the introductory comment (see Classwork 2 for details). The grading scripts will run your program directly on several different test cases, supplying the names of the files. If you do not ask for input in your program (e.g. ask for the input and output file names), the autograder will time-out waiting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
